{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Proof-of-Concept "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, Functions, & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import gzip\n",
    "from nilearn import image, masking, plotting, datasets\n",
    "from nilearn.input_data import NiftiMasker\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "##########################################\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting\n",
    "from nilearn import image\n",
    "from nilearn import regions\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "##########################################\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nilearn.datasets import fetch_atlas_harvard_oxford\n",
    "from scipy.ndimage import zoom\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nilearn.datasets import load_mni152_template\n",
    "from nilearn import plotting\n",
    "from nilearn import datasets\n",
    "from nilearn import plotting\n",
    "\n",
    "\n",
    "from nilearn.plotting import plot_roi\n",
    "\n",
    "from nilearn.image import resample_to_img\n",
    "\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fMRI and anatomical data\n",
    "def load_fmri_data(fmri_filepath):\n",
    "    fmri_img = nib.load(fmri_filepath)\n",
    "    fmri_data = fmri_img.get_fdata()\n",
    "    return fmri_data\n",
    "\n",
    "def load_anatomical_data(anatomical_filepath):\n",
    "    anatomical_img = nib.load(anatomical_filepath)\n",
    "    anatomical_data = anatomical_img.get_fdata()\n",
    "    return anatomical_data\n",
    "\n",
    "def load_nii(file_path):\n",
    "    \"\"\"Load .nii file using nibabel and return data as numpy array.\"\"\"\n",
    "    nii_data = nib.load(file_path)\n",
    "    return nii_data.get_fdata(), nii_data.affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gz_files = [f for f in glob(f\"./data/**/*.gz\", recursive=True) if os.path.isfile(f)]\n",
    "# gz_files\n",
    "# Extract each .gz file\n",
    "# for gz_file in gz_files:\n",
    "#     output_file = gz_file[:-3]  # Remove \".gz\" extension\n",
    "\n",
    "#     # Decompress the .gz file\n",
    "#     with gzip.open(gz_file, 'rb') as f_in:\n",
    "#         with open(output_file, 'wb') as f_out:\n",
    "#             shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "#     print(f\"Extracted: {gz_file} -> {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Func files without mask: []\n",
      "Anat files: []\n",
      "Func mask files: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Root directory is 'data'\n",
    "root_dir = 'data'\n",
    "\n",
    "# Glob all files that end in .nii under any 'func' directory (in nested subfolders)\n",
    "func_files = glob.glob(os.path.join(root_dir, '**', 'func', '**', '*.nii'), recursive=True)\n",
    "\n",
    "# Filter out files that contain the word 'mask' from the func_files list\n",
    "func_files_without_mask = [file for file in func_files if 'mask' not in file]\n",
    "\n",
    "# Glob all files that end in .nii under any 'anat' directory (in nested subfolders)\n",
    "anat_files = glob.glob(os.path.join(root_dir, '**', 'anat', '**', '*.nii'), recursive=True)\n",
    "\n",
    "# Glob all files that contain the word \"mask\" that end in .nii and are located under any 'func' directory (in nested subfolders)\n",
    "func_mask_files = glob.glob(os.path.join(root_dir, '**', 'func', '**', '*mask*.nii'), recursive=True)\n",
    "\n",
    "# Output the results\n",
    "print(\"Func files without mask:\", func_files_without_mask)\n",
    "print(\"Anat files:\", anat_files)\n",
    "print(\"Func mask files:\", func_mask_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anatomical Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "file_list_len = len(func_files_without_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index += 1\n",
    "index %= file_list_len\n",
    "# Load the compressed NIfTI file\n",
    "img = nib.load(anat_files[index])\n",
    "\n",
    "# Get image data as a NumPy array\n",
    "data = img.get_fdata()\n",
    "\n",
    "# Display a middle slice of the brain\n",
    "slice_index = data.shape[2] // 2  # Middle slice in the z-dimension\n",
    "\n",
    "plt.imshow(data[:, :, slice_index], cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"T1-Weighted MRI Slice: \\n{anat_files[index]}\\n index: {index}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anat_files[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_anat(anat_files[index], title=f\"3D Brain Visualization: \\n{anat_files[index]}\", threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anat_data_f_name = anat_files[index]\n",
    "func_data_f_name = func_files_without_mask[index]\n",
    "\n",
    "# Load the compressed NIfTI file\n",
    "img = nib.load(anat_data_f_name)\n",
    "\n",
    "# Get image data as a NumPy array\n",
    "anat_data = img.get_fdata()\n",
    "\n",
    "# Load the compressed NIfTI file\n",
    "img = nib.load(func_data_f_name)\n",
    "\n",
    "# Get image data as a NumPy array\n",
    "func_data = img.get_fdata()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating A Graph Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Process](https://chatgpt.com/share/67dccc80-8f9c-8011-97b0-f044a525470d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intended Result:\n",
    "# This method allows you to visualize the differences in brain activity between individuals using the networkx graph in a 3D space. By using Three.js, you can provide an interactive and detailed representation of the anatomical brain regions and their connections, colored by activity differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 4D fMRI data and 3D anatomical data for each brain\n",
    "brains_fmri = func_files_without_mask\n",
    "brains_anatomical = anat_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: Load the first brain's fMRI and anatomical data\n",
    "fmri_data, fmri_affine = load_nii(brains_fmri[0])  # Shape: (x, y, z, t)\n",
    "anatomical_data, anatomical_affine = load_nii(brains_anatomical[0])  # Shape: (x, y, z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract regions of interest (ROIs) from anatomical data\n",
    "# For simplicity, use a predefined atlas (e.g., Harvard-Oxford or AAL)\n",
    "# from nilearn.datasets import load_mni152_template\n",
    "# from nilearn import plotting\n",
    "\n",
    "# Load the MNI template (in standard space) for visualization\n",
    "# mni_template = load_mni152_template()\n",
    "\n",
    "# Load an atlas, for example, Harvard-Oxford sub-cortical regions\n",
    "# from nilearn import datasets\n",
    "# from nilearn import plotting\n",
    "\n",
    "# Load Harvard-Oxford sub-cortical regions (valid name: sub-maxprob-thr50-1mm)\n",
    "atlas = datasets.fetch_atlas_harvard_oxford('sub-maxprob-thr50-1mm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The atlas is returned as a dictionary with paths to the data\n",
    "print(atlas.filename)  # This is the file path to the MNI space atlas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize the Harvard-Oxford sub-cortical regions\n",
    "plotting.plot_roi(atlas.filename, title=\"Harvard-Oxford Sub-Cortical Regions\", display_mode='ortho', draw_cross=True)\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the NumPy array (anatomical_data) to a NIfTI image using the affine matrix\n",
    "anat_img = nib.Nifti1Image(anatomical_data, anatomical_affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the anatomical image\n",
    "plotting.plot_anat(anat_img, title=\"Brain Anatomy\")\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Region Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 4D fMRI data and 3D anatomical data for each brain\n",
    "brains_fmri = func_files_without_mask\n",
    "brains_anatomical = anat_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"brains_fmri: {brains_fmri[0]}\")\n",
    "print(f\"brains_anatomical: {brains_anatomical[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load the first brain's fMRI and anatomical data\n",
    "fmri_data, fmri_affine = load_nii(brains_fmri[0])  # Shape: (x, y, z, t)\n",
    "anatomical_data, anatomical_affine = load_nii(brains_anatomical[0])  # Shape: (x, y, z)\n",
    "anatomical_nii = nib.load(brains_anatomical[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Atlas shape:\", anatomical_data.shape)  # Should be (X, Y, Z)\n",
    "print(\"fMRI shape:\", fmri_data.shape)  # Should be (X, Y, Z, Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the atlas (cortical or subcortical)\n",
    "\n",
    "# atlas = fetch_atlas_harvard_oxford('cort-maxprob-thr25-1mm')  # 1mm resolution\n",
    "# atlas_img = atlas.maps\n",
    "\n",
    "# Fetch the cortical atlas\n",
    "atlas_cortex = fetch_atlas_harvard_oxford('cort-maxprob-thr25-1mm')\n",
    "atlas_img_cortex = atlas_cortex.maps\n",
    "\n",
    "# Resample the atlas to match the anatomical image\n",
    "resampled_atlas = resample_to_img(atlas_img_cortex, anatomical_nii, interpolation='nearest')\n",
    "# resampled_atlas = resample_to_img(atlas_img, anatomical_nii , interpolation='nearest')\n",
    "\n",
    "# Save the new resampled atlas\n",
    "resampled_atlas.to_filename(\"registered_atlas.nii.gz\")\n",
    "plot_roi(resampled_atlas, bg_img=anatomical_nii, title=\"Registered Harvard-Oxford Atlas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the sub-cortical atlas\n",
    "atlas_subcortical = fetch_atlas_harvard_oxford('sub-maxprob-thr25-1mm')\n",
    "atlas_img_subcortical = atlas_subcortical.filename\n",
    "\n",
    "# Resample the atlas to match the anatomical image\n",
    "resampled_atlas = resample_to_img(atlas_img_subcortical, anatomical_nii, interpolation='nearest')\n",
    "# resampled_atlas = resample_to_img(atlas_img, anatomical_nii , interpolation='nearest')\n",
    "\n",
    "# Save the new resampled atlas\n",
    "resampled_atlas.to_filename(\"registered_atlas.nii.gz\")\n",
    "plot_roi(resampled_atlas, bg_img=anatomical_nii, title=\"Registered Harvard-Oxford Atlas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Regions of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the resampled atlas image to a NumPy array\n",
    "atlas_data = resampled_atlas.get_fdata()\n",
    "\n",
    "# Extract unique region labels from the atlas\n",
    "roi_labels = np.unique(atlas_data)[1:]  # Ignore background (0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(atlas_data == 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Resample the atlas to match the spatial dimensions of fmri_data (64, 64, 34)\n",
    "# Determine the scaling factors for each spatial dimension\n",
    "scaling_factors = np.array(fmri_data.shape[:3]) / np.array(atlas_data.shape)\n",
    "\n",
    "# Resample the atlas using the scaling factors (linear interpolation)\n",
    "resampled_atlas = zoom(atlas_data, scaling_factors, order=1)  # Using linear interpolation\n",
    "\n",
    "# Round and cast the resampled atlas to integers\n",
    "resampled_atlas = np.round(resampled_atlas).astype(int)\n",
    "\n",
    "# Step 2: Extract unique region labels from the resampled atlas (skip background 0)\n",
    "roi_labels = np.unique(resampled_atlas)[np.unique(resampled_atlas) > 0]\n",
    "\n",
    "# Create a dictionary to store extracted time series for each ROI\n",
    "roi_time_series = {}\n",
    "\n",
    "# Step 3: Extract fMRI time series for each ROI\n",
    "for roi in tqdm(roi_labels, desc=\"Processing ROIs\"):\n",
    "    # Get the voxel indices for the current ROI in the resampled atlas\n",
    "    roi_voxels = np.where(resampled_atlas == roi)\n",
    "\n",
    "    # Ensure the voxel indices are valid within the spatial dimensions of fmri_data\n",
    "    # Extract the fMRI signal corresponding to these voxels for each time point\n",
    "    roi_signal = fmri_data[roi_voxels].mean(axis=0)  # Averaging across voxels (axis 0 refers to spatial)\n",
    "\n",
    "    # Store the resulting time series for the current ROI\n",
    "    roi_time_series[roi] = roi_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "roi_df = pd.DataFrame(roi_time_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as CSV\n",
    "roi_df.to_csv(\"roi_activity.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an example ROI signal\n",
    "plt.plot(roi_df.iloc[:, 0], label = atlas_subcortical.labels[1])  # Plot the first region\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"BOLD Signal\")\n",
    "plt.title(\"Region Activity Over Time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an example ROI signal\n",
    "plt.plot(roi_df.iloc[:, index], label = atlas_subcortical.labels[index+1])  # Plot the first region\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"BOLD Signal\")\n",
    "plt.title(f\"{atlas_subcortical.labels[index+1]} Region Activity Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "index +=1\n",
    "index %= roi_df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the ALFF/fALFF and the Bold Variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_df.iloc[:, index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "TR = 2 # Repetition time (in seconds)\n",
    "low_freq_band = (0.01, 0.1) # Low-frequency range for ALFF (Hz)\n",
    "n_timepoints = roi_df.shape[0]\n",
    "frequencies = fftfreq(n_timepoints, d=TR)\n",
    "fft_data = fft(roi_df.iloc[:, index], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a mask for the low-frequency band\n",
    "low_freq_mask = np.logical_and(frequencies >= low_freq_band[0], frequencies <= low_freq_band[1])\n",
    "\n",
    "# Compute the ALFF: average amplitude in the low-frequency band\n",
    "alff = np.abs(fft_data)[..., low_freq_mask].mean(axis=-1)\n",
    "\n",
    "# For fALFF: Compute the total power in the 0.01-0.25 Hz range\n",
    "total_power = np.abs(fft_data)[..., (frequencies >= 0.01) & (frequencies <= 0.25)].sum(axis=-1)\n",
    "\n",
    "# Compute fALFF: Normalized ALFF\n",
    "falff = alff / total_power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOLD Signal Variability (e.g., using Coefficient of Variation)\n",
    "cv = np.std(roi_df.iloc[:, index]) / np.mean(roi_df.iloc[:, index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "falff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- [ ] Creating region_activities all_brains:  a list of dictionaries, where each dictionary maps region names to activity levels\n",
    "- [ ] regions: atlas.labels[1:]\n",
    "- [ ] brains_fmri: exists\n",
    "- [ ] Improvement: increase granularity by having multiple signals from regions where regions correspond to Link-sized regions with 1024 BOLD temporal signals\n",
    "- [ ] Compute the Activity Difference\n",
    "- [ ] Create the Graph\n",
    "- [ ] Export the graph data\n",
    "- [ ] visualize\n",
    "- [ ] host visualization on github pages\n",
    "- [ ] include sub-cortical regions\n",
    "- [ ] cluster the data by age, handedness, sex, and education\n",
    "- [ ] cluster by health, MCI, and Demented\n",
    "- [ ] evaluate level of stimulation to apply to achieve normal cognitive status\n",
    "- [ ] simulate applying stimulation to MCI or Demented to achieve Healthy Cognitive Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquiring All Signals For all Brains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nilearn.plotting.displays._slicers.OrthoSlicer at 0x714189bf1c90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 660x350 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nilearn import datasets, plotting\n",
    "\n",
    "# Fetch the Harvard-Oxford sub-cortical atlas (probabilistic)\n",
    "atlas_filename = \"../data/atlas/NMS-SNc-atlas-master/SN_R_probatlas27_50.nii.gz\"\n",
    "\n",
    "# Plot the atlas to view the regions including substantia nigra\n",
    "plotting.plot_roi(atlas_filename, title=\"Harvard-Oxford Sub-cortical Atlas\", display_mode=\"ortho\", draw_cross=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/atlas/NMS-SNc-atlas-master/SN_L_probatlas27_50.nii.gz'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atlas_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2. -21. -18.]\n",
      " [ -2. -21. -17.]\n",
      " [ -2. -20. -17.]\n",
      " [ -2. -20. -16.]\n",
      " [ -2. -19. -16.]\n",
      " [ -2. -19. -15.]\n",
      " [ -3. -22. -19.]\n",
      " [ -3. -22. -18.]\n",
      " [ -3. -21. -19.]\n",
      " [ -3. -21. -18.]]\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# Load the atlas NIfTI image\n",
    "atlas_img = nib.load(atlas_filename)\n",
    "\n",
    "# Get the image data as a numpy array\n",
    "atlas_data = atlas_img.get_fdata()\n",
    "\n",
    "# Find the nonzero voxel coordinates (i.e., where the atlas has nonzero values)\n",
    "voxel_coords = np.argwhere(atlas_data > 0)\n",
    "\n",
    "# Convert voxel coordinates to real-world (MNI or scanner) space\n",
    "affine = atlas_img.affine\n",
    "world_coords = nib.affines.apply_affine(affine, voxel_coords)\n",
    "\n",
    "# Print first few coordinates\n",
    "print(world_coords[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">get_dataset_dir</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Dataset found in <span style=\"color: #800080; text-decoration-color: #800080\">/home/linux-pc/nilearn_data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">aal_SPM12</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mget_dataset_dir\u001b[0m\u001b[1;34m]\u001b[0m Dataset found in \u001b[35m/home/linux-pc/nilearn_data/\u001b[0m\u001b[95maal_SPM12\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_single_file</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Downloading data from <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://www.gin.cnrs.fr/AAL_files/aal_for_SPM12.tar.gz</span> <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mfetch_single_file\u001b[0m\u001b[1;34m]\u001b[0m Downloading data from \u001b[4;94mhttps://www.gin.cnrs.fr/AAL_files/aal_for_SPM12.tar.gz\u001b[0m \u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">[</span><span style=\"color: #000080; text-decoration-color: #000080\">fetch_single_file</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">]</span> Error while fetching file aal_for_SPM12.tar.gz; dataset fetching aborted.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34m[\u001b[0m\u001b[34mfetch_single_file\u001b[0m\u001b[1;34m]\u001b[0m Error while fetching file aal_for_SPM12.tar.gz; dataset fetching aborted.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "SSLError",
     "evalue": "HTTPSConnectionPool(host='www.gin.cnrs.fr', port=443): Max retries exceeded with url: /AAL_files/aal_for_SPM12.tar.gz (Caused by SSLError(SSLCertVerificationError(1, \"[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'www.gin.cnrs.fr'. (_ssl.c:1007)\")))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/urllib3/connectionpool.py:464\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/urllib3/connectionpool.py:1093\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1093\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/urllib3/connection.py:741\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m server_hostname_rm_dot \u001b[38;5;241m=\u001b[39m server_hostname\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 741\u001b[0m sock_and_verified \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock_and_verified\u001b[38;5;241m.\u001b[39msocket\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/urllib3/connection.py:920\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[0;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[1;32m    918\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m normalized\n\u001b[0;32m--> 920\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/urllib3/util/ssl_.py:460\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    458\u001b[0m context\u001b[38;5;241m.\u001b[39mset_alpn_protocols(ALPN_PROTOCOLS)\n\u001b[0;32m--> 460\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/urllib3/util/ssl_.py:504\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[0;32m--> 504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/ssl.py:513\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    508\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    509\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    510\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/ssl.py:1375\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1375\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'www.gin.cnrs.fr'. (_ssl.c:1007)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/urllib3/connectionpool.py:488\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    487\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "\u001b[0;31mSSLError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'www.gin.cnrs.fr'. (_ssl.c:1007)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/urllib3/connectionpool.py:841\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    839\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 841\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.gin.cnrs.fr', port=443): Max retries exceeded with url: /AAL_files/aal_for_SPM12.tar.gz (Caused by SSLError(SSLCertVerificationError(1, \"[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'www.gin.cnrs.fr'. (_ssl.c:1007)\")))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the AAL Atlas\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m atlas \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_atlas_aal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/nilearn/datasets/atlas.py:1323\u001b[0m, in \u001b[0;36mfetch_atlas_aal\u001b[0;34m(version, data_dir, url, resume, verbose)\u001b[0m\n\u001b[1;32m   1316\u001b[0m         filenames \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1317\u001b[0m             (Path(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maal_for_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, f), url, opts) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m basenames\n\u001b[1;32m   1318\u001b[0m         ]\n\u001b[1;32m   1320\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m get_dataset_dir(\n\u001b[1;32m   1321\u001b[0m     dataset_name, data_dir\u001b[38;5;241m=\u001b[39mdata_dir, verbose\u001b[38;5;241m=\u001b[39mverbose\n\u001b[1;32m   1322\u001b[0m )\n\u001b[0;32m-> 1323\u001b[0m atlas_img, labels_file \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m fdescr \u001b[38;5;241m=\u001b[39m get_dataset_descr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1327\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/nilearn/datasets/_utils.py:770\u001b[0m, in \u001b[0;36mfetch_files\u001b[0;34m(data_dir, files, resume, verbose, session)\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m sess:\n\u001b[1;32m    769\u001b[0m         sess\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mftp:\u001b[39m\u001b[38;5;124m\"\u001b[39m, _NaiveFTPAdapter())\n\u001b[0;32m--> 770\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfetch_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m            \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;66;03m# There are two working directories here:\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;66;03m# - data_dir is the destination directory of the dataset\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;66;03m# - temp_dir is a temporary directory dedicated to this fetching call. All\u001b[39;00m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;66;03m#   files that must be downloaded will be in this directory. If a corrupted\u001b[39;00m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;66;03m#   file is found, or a file is missing, this working directory will be\u001b[39;00m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;66;03m#   deleted.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(files)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/nilearn/datasets/_utils.py:825\u001b[0m, in \u001b[0;36mfetch_files\u001b[0;34m(data_dir, files, resume, verbose, session)\u001b[0m\n\u001b[1;32m    822\u001b[0m temp_dir\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    823\u001b[0m md5sum \u001b[38;5;241m=\u001b[39m opts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmd5sum\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 825\u001b[0m dl_file \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_single_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemp_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmd5sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmd5sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43musername\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musername\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpassword\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmove\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m opts:\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;66;03m# XXX: here, move is supposed to be a dir, it can be a name\u001b[39;00m\n\u001b[1;32m    838\u001b[0m     move \u001b[38;5;241m=\u001b[39m temp_dir \u001b[38;5;241m/\u001b[39m opts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmove\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/nilearn/datasets/_utils.py:644\u001b[0m, in \u001b[0;36mfetch_single_file\u001b[0;34m(url, data_dir, resume, overwrite, md5sum, username, password, verbose, session)\u001b[0m\n\u001b[1;32m    640\u001b[0m req \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    641\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39murl, headers\u001b[38;5;241m=\u001b[39mheaders, auth\u001b[38;5;241m=\u001b[39mauth\n\u001b[1;32m    642\u001b[0m )\n\u001b[1;32m    643\u001b[0m prepped \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mprepare_request(req)\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprepped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_REQUESTS_TIMEOUT\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m resp:\n\u001b[1;32m    647\u001b[0m     resp\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m temp_full_name\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/requests/adapters.py:698\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ProxyError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    697\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m--> 698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mSSLError\u001b[0m: HTTPSConnectionPool(host='www.gin.cnrs.fr', port=443): Max retries exceeded with url: /AAL_files/aal_for_SPM12.tar.gz (Caused by SSLError(SSLCertVerificationError(1, \"[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'www.gin.cnrs.fr'. (_ssl.c:1007)\")))"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the AAL Atlas\n",
    "atlas = datasets.fetch_atlas_aal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(flat_list).to_csv(\"temp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "matches = [(i, item) for i, item in enumerate(flat_list) if \"Substantia Nigra\" in item]\n",
    "\n",
    "print(matches)  \n",
    "# Output: [(2, 'Substantia Nigra Left'), (4, 'Substantia Nigra Right')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid atlas name: sub-cortical. Please choose an atlas among:\ncort-maxprob-thr0-1mm\ncort-maxprob-thr0-2mm\ncort-maxprob-thr25-1mm\ncort-maxprob-thr25-2mm\ncort-maxprob-thr50-1mm\ncort-maxprob-thr50-2mm\ncort-prob-1mm\ncort-prob-2mm\ncortl-maxprob-thr0-1mm\ncortl-maxprob-thr0-2mm\ncortl-maxprob-thr25-1mm\ncortl-maxprob-thr25-2mm\ncortl-maxprob-thr50-1mm\ncortl-maxprob-thr50-2mm\ncortl-prob-1mm\ncortl-prob-2mm\nsub-maxprob-thr0-1mm\nsub-maxprob-thr0-2mm\nsub-maxprob-thr25-1mm\nsub-maxprob-thr25-2mm\nsub-maxprob-thr50-1mm\nsub-maxprob-thr50-2mm\nsub-prob-1mm\nsub-prob-2mm",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m atlas_filename \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_atlas_harvard_oxford\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msub-cortical\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.10/site-packages/nilearn/datasets/atlas.py:487\u001b[0m, in \u001b[0;36mfetch_atlas_harvard_oxford\u001b[0;34m(atlas_name, data_dir, symmetric_split, resume, verbose)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m atlas_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m atlases:\n\u001b[1;32m    486\u001b[0m     atlases \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(atlases)\n\u001b[0;32m--> 487\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    488\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid atlas name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00matlas_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    489\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease choose an atlas among:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00matlases\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m     )\n\u001b[1;32m    491\u001b[0m is_probabilistic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-prob-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m atlas_name\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_probabilistic \u001b[38;5;129;01mand\u001b[39;00m symmetric_split:\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid atlas name: sub-cortical. Please choose an atlas among:\ncort-maxprob-thr0-1mm\ncort-maxprob-thr0-2mm\ncort-maxprob-thr25-1mm\ncort-maxprob-thr25-2mm\ncort-maxprob-thr50-1mm\ncort-maxprob-thr50-2mm\ncort-prob-1mm\ncort-prob-2mm\ncortl-maxprob-thr0-1mm\ncortl-maxprob-thr0-2mm\ncortl-maxprob-thr25-1mm\ncortl-maxprob-thr25-2mm\ncortl-maxprob-thr50-1mm\ncortl-maxprob-thr50-2mm\ncortl-prob-1mm\ncortl-prob-2mm\nsub-maxprob-thr0-1mm\nsub-maxprob-thr0-2mm\nsub-maxprob-thr25-1mm\nsub-maxprob-thr25-2mm\nsub-maxprob-thr50-1mm\nsub-maxprob-thr50-2mm\nsub-prob-1mm\nsub-prob-2mm"
     ]
    }
   ],
   "source": [
    "atlas_filename = datasets.fetch_atlas_harvard_oxford('sub-cortical')['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fetch_atlas_harvard_oxford' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fetch the atlas (cortical or subcortical)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m atlas_cortex \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_atlas_harvard_oxford\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcort-maxprob-thr25-1mm\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 1mm resolution\u001b[39;00m\n\u001b[1;32m      3\u001b[0m atlas_img_cortex \u001b[38;5;241m=\u001b[39m atlas\u001b[38;5;241m.\u001b[39mfilename\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Fetch the sub-cortical atlas\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fetch_atlas_harvard_oxford' is not defined"
     ]
    }
   ],
   "source": [
    "# Fetch the atlas (cortical or subcortical)\n",
    "atlas_cortex = fetch_atlas_harvard_oxford('cort-maxprob-thr25-1mm')  # 1mm resolution\n",
    "atlas_img_cortex = atlas.filename\n",
    "\n",
    "# Fetch the sub-cortical atlas\n",
    "atlas_subcortical = fetch_atlas_harvard_oxford('sub-maxprob-thr25-1mm')\n",
    "atlas_img_subcortical = atlas_subcortical.filename\n",
    "\n",
    "# Load the Harvard-Oxford Sub-cortical Atlas\n",
    "# from nilearn import datasets\n",
    "# atlas_filename = datasets.fetch_atlas_harvard_oxford('sub-cortical')['filename']\n",
    "\n",
    "# Plot the Harvard-Oxford Sub-cortical Atlas overlaid on the fMRI data\n",
    "# plotting.plot_roi(atlas_filename, bg_img=fmri_data, title=\"Harvard-Oxford Sub-cortical Atlas\")\n",
    "\n",
    "\n",
    "atlas_labels = atlas_cortex.labels[1:] + atlas_subcortical.labels[1:]\n",
    "\n",
    "# Root directory is 'data'\n",
    "root_dir = '../data'\n",
    "\n",
    "# Glob all files that end in .nii under any 'func' directory (in nested subfolders)\n",
    "func_files = glob.glob(os.path.join(root_dir, '**', 'func', '**', '*.nii.gz'), recursive=True)\n",
    "\n",
    "# Filter out files that contain the word 'mask' from the func_files list\n",
    "func_files_without_mask = [file for file in func_files if 'mask' not in file]\n",
    "\n",
    "# Glob all files that end in .nii under any 'anat' directory (in nested subfolders)\n",
    "anat_files = glob.glob(os.path.join(root_dir, '**', 'anat', '**', '*.nii.gz'), recursive=True)\n",
    "\n",
    "# Glob all files that contain the word \"mask\" that end in .nii and are located under any 'func' directory (in nested subfolders)\n",
    "func_mask_files = glob.glob(os.path.join(root_dir, '**', 'func', '**', '*mask*.nii.gz'), recursive=True)\n",
    "\n",
    "# Output the results\n",
    "print(\"Func files without mask:\", func_files_without_mask)\n",
    "print(\"Anat files:\", anat_files)\n",
    "print(\"Func mask files:\", func_mask_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 4D fMRI data and 3D anatomical data for each brain\n",
    "brains_fmri = func_files_without_mask\n",
    "brains_anatomical = anat_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(brains_anatomical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(brains_fmri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bold Signals For All Subcortical and Cortical Regions\n",
    "for person in tqdm(range(len(brains_fmri))):\n",
    "    bold_signal_dir = os.path.dirname(os.path.dirname(brains_fmri[person]))\n",
    "    subject_name = os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(brains_fmri[person]))))\n",
    "    # Example: Load the first brain's fMRI and anatomical data\n",
    "    fmri_data, fmri_affine = load_nii(brains_fmri[person])  # Shape: (x, y, z, t)\n",
    "    anatomical_data, anatomical_affine = load_nii(brains_anatomical[person])  # Shape: (x, y, z)\n",
    "    anatomical_nii = nib.load(brains_anatomical[person])\n",
    "    \n",
    "    # Resample the atlas to match the anatomical image (cortical)\n",
    "    resampled_atlas_cortex = resample_to_img(atlas_img_cortex, anatomical_nii , interpolation='nearest')\n",
    "    resampled_atlas_subcortex = resample_to_img(atlas_img_subcortical, anatomical_nii , interpolation='nearest')\n",
    "    \n",
    "    # Save the new resampled atlas\n",
    "    # resampled_atlas.to_filename(\"registered_atlas.nii.gz\")\n",
    "    \n",
    "    # Convert the resampled atlas image to a NumPy array\n",
    "    atlas_data_cortex = resampled_atlas_cortex.get_fdata()\n",
    "    atlas_data_subcortex = resampled_atlas_subcortex.get_fdata()\n",
    "    \n",
    "    # Extract unique region labels from the atlas\n",
    "    roi_labels_cortex = np.unique(atlas_data_cortex)[1:]  # Ignore background (0)\n",
    "    roi_labels_subcortex = np.unique(atlas_data_subcortex)[1:]  # Ignore background (0)roi_labels_cortex = np.unique(atlas_data_cortex)[1:]  # Ignore background (0)\n",
    "\n",
    "    # Step 1: Resample the atlas to match the spatial dimensions of fmri_data (64, 64, 34)\n",
    "    # Determine the scaling factors for each spatial dimension\n",
    "    scaling_factors = np.array(fmri_data.shape[:3]) / np.array(atlas_data_cortex.shape)\n",
    "\n",
    "    # Resample the atlas using the scaling factors (linear interpolation)\n",
    "    resampled_atlas_cortex = zoom(atlas_data_cortex, scaling_factors, order=1)  # Using linear interpolation\n",
    "    resampled_atlas_subcortex = zoom(atlas_data_subcortex, scaling_factors, order=1) # Using linear inerpolation\n",
    "\n",
    "    # Round and cast the resampled atlas to integers\n",
    "    resampled_atlas_cortex = np.round(resampled_atlas_cortex).astype(int)\n",
    "    resampled_atlas_subcortex = np.round(resampled_atlas_subcortex).astype(int)\n",
    "\n",
    "    # Step 2: Extract unique region labels from the resampled atlas (skip background 0)\n",
    "    # roi_labels = np.unique(resampled_atlas)[np.unique(resampled_atlas) > 0]\n",
    "\n",
    "    # Create a dictionary to store extracted time series for each ROI\n",
    "    roi_time_series = {}\n",
    "\n",
    "    # Step 3: Extract fMRI time series for each ROI\n",
    "    for roi in tqdm(roi_labels_cortex, desc=\"Processing ROIs\"):\n",
    "        # Get the voxel indices for the current ROI in the resampled atlas\n",
    "        roi_voxels = np.where(resampled_atlas_cortex == roi)\n",
    "\n",
    "        # Ensure the voxel indices are valid within the spatial dimensions of fmri_data\n",
    "        # Extract the fMRI signal corresponding to these voxels for each time point\n",
    "        roi_signal = fmri_data[roi_voxels].mean(axis=0)  # Averaging across voxels (axis 0 refers to spatial)\n",
    "\n",
    "        # Store the resulting time series for the current ROI\n",
    "        roi_time_series[roi] = roi_signal\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    roi_cortex_df = pd.DataFrame(roi_time_series)\n",
    "\n",
    "    # Create a dictionary to store extracted time series for each ROI\n",
    "    roi_time_series = {}\n",
    "\n",
    "    # Step 3: Extract fMRI time series for each ROI\n",
    "    for roi in tqdm(roi_labels_subcortex, desc=\"Processing ROIs\"):\n",
    "        # Get the voxel indices for the current ROI in the resampled atlas\n",
    "        roi_voxels = np.where(resampled_atlas_subcortex == roi)\n",
    "\n",
    "        # Ensure the voxel indices are valid within the spatial dimensions of fmri_data\n",
    "        # Extract the fMRI signal corresponding to these voxels for each time point\n",
    "        roi_signal = fmri_data[roi_voxels].mean(axis=0)  # Averaging across voxels (axis 0 refers to spatial)\n",
    "\n",
    "        # Store the resulting time series for the current ROI\n",
    "        roi_time_series[roi] = roi_signal\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    roi_subcortex_df = pd.DataFrame(roi_time_series)\n",
    "    roi_df = pd.concat([roi_cortex_df, roi_subcortex_df], axis=1)\n",
    "    roi_df.columns = atlas_labels\n",
    "\n",
    "    f_path = bold_signal_dir + '/' + subject_name + \"_roi_BOLD_activity.csv\"\n",
    "\n",
    "    # Save as CSV\n",
    "    bold_signal_dir\n",
    "    # roi_df.to_csv(f_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting CSV of BOLD Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 4D fMRI data and 3D anatomical data for each brain\n",
    "brains_fmri = func_files_without_mask\n",
    "brains_anatomical = anat_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOLD_activity_csv_list =[f for f in glob.glob(\"data/**/*.csv\", recursive=True) if \"dataframes\" not in f ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOLD_activity_csv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the atlas (cortical or subcortical)\n",
    "atlas_cortex = fetch_atlas_harvard_oxford('cort-maxprob-thr25-1mm')  # 1mm resolution\n",
    "atlas_img_cortex = atlas_cortex.filename\n",
    "\n",
    "# Fetch the sub-cortical atlas\n",
    "atlas_subcortical = fetch_atlas_harvard_oxford('sub-maxprob-thr25-1mm')\n",
    "atlas_img_subcortical = atlas_subcortical.filename\n",
    "\n",
    "atlas_labels = atlas_cortex.labels[1:] + atlas_subcortical.labels[1:]\n",
    "atlas_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOLD_activity_df_list = []\n",
    "for person in BOLD_activity_csv_list:\n",
    "    BOLD_activity_df_list.append(pd.read_csv(person))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Computing fractional Amplitude Low Frequency Fluctuations & Coefficient of Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fALFF_df = pd.DataFrame(columns=[\"Subject\"] + atlas_labels)\n",
    "cv_df = pd.DataFrame(columns=[\"Subject\"] + atlas_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "TR = 2 # Repetition time (in seconds)\n",
    "low_freq_band = (0.01, 0.1) # Low-frequency range for ALFF (Hz)\n",
    "n_timepoints = 300\n",
    "frequencies = fftfreq(n_timepoints, d=TR)\n",
    "# Create a mask for the low-frequency band\n",
    "low_freq_mask = np.logical_and(frequencies >= low_freq_band[0], frequencies <= low_freq_band[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft(BOLD_activity_df_list[0].iloc[:, 1], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for temp_df in BOLD_activity_df_list:\n",
    "    for region in range(len(temp_df.columns)):\n",
    "        # print(temp_df.iloc[:, region])\n",
    "        print(temp_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.iloc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for temp_df in BOLD_activity_df_list:\n",
    "    for region in range(len(temp_df.columns)):\n",
    "        print(temp_df.iloc[:, region])\n",
    "        print(type(region))\n",
    "        # fft_data = fft(temp_df.iloc[:, region], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Frequencies and CV\n",
    "person = 0\n",
    "for temp_df in tqdm(BOLD_activity_df_list):\n",
    "    subject_name = os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(brains_fmri[person]))))\n",
    "    fALFF_values = []\n",
    "    cv_values = []\n",
    "    for region in range(len(temp_df.columns)):\n",
    "        fft_data = fft(temp_df.iloc[:, region], axis=-1)\n",
    "        \n",
    "        # Compute the ALFF: average amplitude in the low-frequency band\n",
    "        alff = np.abs(fft_data)[..., low_freq_mask].mean(axis=-1)\n",
    "\n",
    "        # For fALFF: Compute the total power in the 0.01-0.25 Hz range\n",
    "        total_power = np.abs(fft_data)[..., (frequencies >= 0.01) & (frequencies <= 0.25)].sum(axis=-1)\n",
    "\n",
    "        # Compute fALFF: Normalized ALFF\n",
    "        falff = alff / total_power\n",
    "        fALFF_values.append(falff)\n",
    "        \n",
    "        # BOLD Signal Variability (e.g., using Coefficient of Variation)\n",
    "        cv = np.std(temp_df.iloc[:, region]) / np.mean(temp_df.iloc[:, region])\n",
    "        cv_values.append(cv)\n",
    "    \n",
    "    # Create the new row with \"Subject\" and the numerical values\n",
    "    new_row = {'Subject': subject_name}  # Add the string value for 'Subject'\n",
    "    new_row.update(dict(zip(atlas_labels, fALFF_values)))  # Add numerical values to the other columns\n",
    "    fALFF_df.loc[len(fALFF_df)] = new_row\n",
    "    \n",
    "    new_row = {'Subject': subject_name}\n",
    "    new_row.update(dict(zip(atlas_labels, cv_values)))\n",
    "    cv_df.loc[len(cv_df)] = new_row\n",
    "    person+=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(BOLD_activity_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subject_name_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dir = \"data/dataframes/BOLD/\"\n",
    "for df in tqdm(range(len(BOLD_activity_df_list))):\n",
    "    BOLD_activity_df_list[df].to_csv(df_dir + subject_name_l[df] + \"_BOLD.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fALFF_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the 'Subject' column as the index for easy access\n",
    "fALFF_df.set_index('Subject', inplace=True)\n",
    "cv_df.set_index('Subject', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save fALFF_df & cv df\n",
    "fALFF_df.to_csv(\"data/dataframes/fALFF.csv\")  # Save without the index\n",
    "cv_df.to_csv(\"data/dataframes/cv_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquiring subject names:\n",
    "subject_name_l = []\n",
    "for person in range(len(brains_fmri)):\n",
    "    subject_name = os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(brains_fmri[person]))))\n",
    "    subject_name_l.append(subject_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_name_df = pd.DataFrame(subject_name_l, columns=['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_name_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_name_df.to_csv(\"data/dataframes/subject_name_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the fALFF & CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fALFF & CV\n",
    "fALFF_df = pd.read_csv(\"data/dataframes/fALFF.csv\", index_col=0)\n",
    "cv_df = pd.read_csv(\"data/dataframes/cv_df.csv\", index_col=0)\n",
    "subject_name_df = pd.read_csv(\"data/dataframes/subject_name_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_name_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fALFF_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOLD_activity_df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty bipartite graph\n",
    "B = nx.Graph()\n",
    "\n",
    "# Add nodes for subjects (bipartite set 1)\n",
    "B.add_nodes_from(fALFF_df.index, bipartite=0)\n",
    "\n",
    "# Add nodes for regions (bipartite set 2)\n",
    "regions = fALFF_df.columns.tolist()  # All regions are the columns of fALFF_df\n",
    "B.add_nodes_from(regions, bipartite=1)\n",
    "\n",
    "# Add edges between subjects and regions with two distinct weights (one from fALFF_df and one from cv_df)\n",
    "for subject in fALFF_df.index:\n",
    "    for region in fALFF_df.columns:\n",
    "        weight1 = fALFF_df.at[subject, region]  # Weight from fALFF_df\n",
    "        weight2 = cv_df.at[subject, region]  # Weight from cv_df\n",
    "        \n",
    "        # Add an edge with two distinct weights\n",
    "        B.add_edge(subject, region, weight_fALFF=weight1, weight_cv=weight2)\n",
    "\n",
    "# Now the graph B contains bipartite nodes (subjects and regions) with edges having two distinct weights\n",
    "\n",
    "# Example: Print the edges with weights from both dataframes\n",
    "for u, v, data in B.edges(data=True):\n",
    "    print(f\"Edge ({u}, {v}) - Weight from fALFF_df: {data['weight_fALFF']}, Weight from cv_df: {data['weight_cv']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Set positions for bipartite layout with increased spacing\n",
    "pos = {}\n",
    "pos.update((node, (1, index * 2.5)) for index, node in enumerate(fALFF_df.index))  # Subjects (left side)\n",
    "pos.update((node, (4, index * 2.5)) for index, node in enumerate(regions))  # Regions (right side)\n",
    "\n",
    "# Get edge weights from the fALFF_df's weight column\n",
    "edge_weights = [B[u][v]['weight_fALFF'] for u, v in B.edges()]\n",
    "\n",
    "# Normalize edge thickness for better visibility\n",
    "max_weight = max(edge_weights) if edge_weights else 1  # Avoid division by zero\n",
    "edge_widths = [1 + 6 * (w / max_weight) for w in edge_weights]  # Scale thickness between 1 and 7\n",
    "\n",
    "# Normalize edge color mapping\n",
    "norm = mcolors.Normalize(vmin=min(edge_weights), vmax=max(edge_weights))\n",
    "cmap = cm.Blues\n",
    "edge_colors = [cmap(norm(w)) for w in edge_weights]\n",
    "\n",
    "# Set larger figure size\n",
    "plt.figure(figsize=(24, 16))  # Bigger canvas for better visibility\n",
    "\n",
    "# Draw the bipartite graph with smaller nodes\n",
    "edges = nx.draw_networkx_edges(\n",
    "    B, pos, edge_color=edge_colors, width=edge_widths, edge_cmap=cmap, alpha=0.8\n",
    ")\n",
    "nodes = nx.draw_networkx_nodes(B, pos, node_size=800, node_color='skyblue')  # Smaller nodes\n",
    "labels = nx.draw_networkx_labels(B, pos, font_size=12, font_weight='bold')\n",
    "\n",
    "# Add colorbar legend for edge weights\n",
    "sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=plt.gca(), orientation='vertical', fraction=0.02, pad=0.02)\n",
    "cbar.set_label(\"Edge Weight (fALFF)\", fontsize=14)\n",
    "\n",
    "# Title\n",
    "plt.title(\"Optimized Bipartite Graph with Improved Spacing and Smaller Nodes\", fontsize=16)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the region to visualize\n",
    "region_to_visualize = \"Frontal Pole\"\n",
    "\n",
    "# Create an empty graph\n",
    "B = nx.Graph()\n",
    "\n",
    "# Add the central brain region node\n",
    "B.add_node(region_to_visualize, color='Teal', size=3000)\n",
    "\n",
    "# Add subject nodes and edges\n",
    "for subject in fALFF_df.index:\n",
    "    weight1 = fALFF_df.at[subject, region_to_visualize]  # fALFF weight\n",
    "    weight2 = cv_df.at[subject, region_to_visualize] if region_to_visualize in cv_df.columns else 0  # CV weight\n",
    "    \n",
    "    B.add_node(subject, color='green', size=1500)  # Subject nodes\n",
    "    B.add_edge(subject, region_to_visualize, weight1=weight1, weight2=weight2)  # Edge with weights\n",
    "\n",
    "# Set figure size **before drawing**\n",
    "plt.figure(figsize=(18, 14))  # Larger figure size for better visibility\n",
    "\n",
    "# Positioning: Use `spring_layout` with a **higher `k` value** to spread nodes more\n",
    "pos = nx.spring_layout(B, seed=42, k=1.5)  # Increase k for wider spacing\n",
    "\n",
    "# Draw nodes with custom sizes and colors\n",
    "node_colors = [B.nodes[node]['color'] for node in B.nodes()]\n",
    "node_sizes = [B.nodes[node]['size'] for node in B.nodes()]\n",
    "nx.draw(B, pos, with_labels=True, node_size=node_sizes, node_color=node_colors, font_size=12, font_weight='bold')\n",
    "\n",
    "# Draw edges with labels (4 decimal places)\n",
    "edge_labels = {\n",
    "    (u, v): f\"fALFF: {B[u][v]['weight1']:.4f}\\nCV: {B[u][v]['weight2']:.4f}\" \n",
    "    for u, v in B.edges()\n",
    "}\n",
    "nx.draw_networkx_edge_labels(B, pos, edge_labels=edge_labels, font_size=10)\n",
    "\n",
    "# Title\n",
    "plt.title(f\"Graph Representation: '{region_to_visualize}' Connected to Subjects\", fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Activity Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Assuming `region_activities_all_brains` is a list of dictionaries, where each dictionary maps region names to activity levels\n",
    "# regions = List of brain regions\n",
    "# brains_fmri = List of brain names or identifiers\n",
    "\n",
    "# Loop through each pair of brains (individuals)\n",
    "for i, brain_1 in enumerate(brains_fmri):\n",
    "    for j, brain_2 in enumerate(brains_fmri):\n",
    "        if i < j:  # Make sure you don't compare the same brain to itself\n",
    "            # Loop through each region to calculate the difference for each region separately\n",
    "            for region in regions:\n",
    "                # Calculate the absolute difference in activity for this region between the two brains\n",
    "                activity_diff = np.abs(region_activities_all_brains[i][region] - region_activities_all_brains[j][region])\n",
    "                \n",
    "                # Add an edge between the two brains for this region, with weight as the activity difference for this region\n",
    "                G.add_edge(f\"{brain_1}_{region}\", f\"{brain_2}_{region}\", weight=activity_diff)\n",
    "\n",
    "# Now `G` contains edges where each edge represents the activity difference for a specific region between two brains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Points:\n",
    "\n",
    "    Graph Structure: Each pair of brains (brain_1 and brain_2) has a separate edge for each region in the brain, with the edge weight representing the difference in activity for that specific region.\n",
    "    Edges Represent Region-Specific Differences: The graph G will have edges named like brain_1_region_name to brain_2_region_name, where region_name corresponds to a specific brain region (e.g., \"hippocampus\", \"prefrontal_cortex\", etc.). The weight of the edge will represent the difference in activity for that region.\n",
    "\n",
    "Example of the Graph Structure:\n",
    "\n",
    "    If there are three brains (brain_1, brain_2, brain_3) and three regions (region_1, region_2, region_3), the graph will have edges like:\n",
    "        brain_1_region_1 to brain_2_region_1 (weight = difference in activity for region_1 between brain_1 and brain_2)\n",
    "        brain_1_region_2 to brain_2_region_2 (weight = difference in activity for region_2 between brain_1 and brain_2)\n",
    "        etc.\n",
    "\n",
    "Usage:\n",
    "\n",
    "    You can then visualize the graph, where each region will have its own node connecting the brains.\n",
    "    You can also use this graph to explore how the activity differences between individual brains vary across regions, which could give insights into specific regional brain activity changes between individuals.\n",
    "\n",
    "If you'd like to visualize or analyze the resulting graph, you can plot the graph using matplotlib, networkx's built-in plotting functions, or any other visualization library you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `G` is your networkx graph (created in the previous step)\n",
    "\n",
    "# Set up the figure\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "# Draw the networkx graph\n",
    "pos = nx.spring_layout(G, k=0.15, iterations=20)  # Layout for positioning nodes\n",
    "nx.draw(G, pos, with_labels=True, node_size=500, node_color=\"lightblue\", font_size=10, font_weight=\"bold\", edge_color='gray')\n",
    "\n",
    "# Add edge labels (weights for the activity differences)\n",
    "edge_labels = nx.get_edge_attributes(G, 'weight')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "\n",
    "# Display the plot\n",
    "plt.title(\"Brain Activity Differences Between Individuals\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "    spring_layout: This layout is good for general graph visualization. It arranges nodes in 2D space with a force-directed algorithm.\n",
    "    nx.draw(): Draws the nodes and edges.\n",
    "    nx.draw_networkx_edge_labels(): Displays the edge labels, which in this case are the activity differences between regions for each brain pair.\n",
    "\n",
    "This Python code will provide a basic 2D visualization. However, for a 3D interactive plot, you need to export the data and use it with Three.js.\n",
    "Step 2: 3D Visualization with Three.js\n",
    "\n",
    "To visualize the same graph in 3D using Three.js, we need to:\n",
    "\n",
    "    Export the graph data (nodes and edges with weights) into a format that Three.js can use (like JSON).\n",
    "    Create the Three.js scene to visualize the nodes and edges.\n",
    "\n",
    "2.1: Exporting the Graph Data to JSON (Python)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Prepare graph data in a format suitable for Three.js\n",
    "graph_data = {\n",
    "    \"nodes\": [],\n",
    "    \"edges\": []\n",
    "}\n",
    "\n",
    "# Add nodes (brains and regions)\n",
    "for node in G.nodes:\n",
    "    # Extract brain and region from node (e.g., brain_1_region_1)\n",
    "    brain, region = node.split('_')\n",
    "    graph_data[\"nodes\"].append({\n",
    "        \"id\": node,\n",
    "        \"brain\": brain,\n",
    "        \"region\": region\n",
    "    })\n",
    "\n",
    "# Add edges (activity differences between brain pairs)\n",
    "for u, v, data in G.edges(data=True):\n",
    "    graph_data[\"edges\"].append({\n",
    "        \"source\": u,\n",
    "        \"target\": v,\n",
    "        \"weight\": data[\"weight\"]\n",
    "    })\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"graph_data.json\", \"w\") as f:\n",
    "    json.dump(graph_data, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generate a graph_data.json file that contains the nodes (with regions and brain identifiers) and edges (with weights representing the activity differences).\n",
    "2.2: Setting Up Three.js for 3D Visualization\n",
    "\n",
    "Now, lets create the 3D visualization in Three.js. Below is an example of how you can visualize the nodes and edges of your graph in 3D.\n",
    "\n",
    "Here is the basic Three.js setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Brain Activity Differences Visualization</title>\n",
    "    <style>\n",
    "        body { margin: 0; overflow: hidden; }\n",
    "        canvas { display: block; }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js\"></script>\n",
    "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/OrbitControls.min.js\"></script>\n",
    "\n",
    "<script>\n",
    "// Set up the 3D scene, camera, and renderer\n",
    "const scene = new THREE.Scene();\n",
    "const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);\n",
    "const renderer = new THREE.WebGLRenderer();\n",
    "renderer.setSize(window.innerWidth, window.innerHeight);\n",
    "document.body.appendChild(renderer.domElement);\n",
    "\n",
    "// Load graph data from the JSON file\n",
    "fetch('graph_data.json')\n",
    "    .then(response => response.json())\n",
    "    .then(graphData => {\n",
    "        const nodes = graphData.nodes;\n",
    "        const edges = graphData.edges;\n",
    "\n",
    "        // Add nodes to the scene (each node is a sphere)\n",
    "        const nodeRadius = 0.5;\n",
    "        const nodeGeometry = new THREE.SphereGeometry(nodeRadius, 16, 16);\n",
    "        const nodeMaterial = new THREE.MeshBasicMaterial({ color: 0x00ff00 });\n",
    "        const nodeMeshes = {};\n",
    "\n",
    "        nodes.forEach(node => {\n",
    "            const nodeMesh = new THREE.Mesh(nodeGeometry, nodeMaterial);\n",
    "            // Random positions for nodes, but can be improved later with better layout algorithms\n",
    "            nodeMesh.position.set(Math.random() * 10 - 5, Math.random() * 10 - 5, Math.random() * 10 - 5);\n",
    "            scene.add(nodeMesh);\n",
    "            nodeMeshes[node.id] = nodeMesh;\n",
    "        });\n",
    "\n",
    "        // Add edges between nodes (lines)\n",
    "        const edgeMaterial = new THREE.LineBasicMaterial({ color: 0x0000ff });\n",
    "        edges.forEach(edge => {\n",
    "            const source = nodeMeshes[edge.source];\n",
    "            const target = nodeMeshes[edge.target];\n",
    "            if (source && target) {\n",
    "                const points = [];\n",
    "                points.push(source.position);\n",
    "                points.push(target.position);\n",
    "                const lineGeometry = new THREE.BufferGeometry().setFromPoints(points);\n",
    "                const line = new THREE.Line(lineGeometry, edgeMaterial);\n",
    "                scene.add(line);\n",
    "            }\n",
    "        });\n",
    "\n",
    "        // Set up the camera position\n",
    "        camera.position.z = 20;\n",
    "\n",
    "        // Add orbit controls to move around the scene\n",
    "        const controls = new THREE.OrbitControls(camera, renderer.domElement);\n",
    "\n",
    "        // Animation loop\n",
    "        function animate() {\n",
    "            requestAnimationFrame(animate);\n",
    "            \n",
    "            // Update the controls to enable interaction\n",
    "            controls.update(); // only required if controls.enableDamping or controls.auto-rotation is enabled\n",
    "            \n",
    "            renderer.render(scene, camera);\n",
    "        }\n",
    "        animate();\n",
    "    });\n",
    "\n",
    "</script>\n",
    "\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "source": [
    "Explanation:\n",
    "\n",
    "    Three.js Setup: The script sets up a basic 3D scene with a camera, lighting, and controls for rotating the view.\n",
    "    Graph Data: The graph data (graph_data.json) is loaded into the scene. Nodes are visualized as spheres, and edges are represented as lines connecting the nodes.\n",
    "    Node and Edge Visualization: The nodes are positioned randomly for simplicity, but you can improve the layout with algorithms such as force-directed layout. The edges are created by connecting pairs of nodes.\n",
    "\n",
    "How to Host on GitHub:\n",
    "\n",
    "    Push the graph_data.json file and your Three.js HTML file to your GitHub repository.\n",
    "    Use GitHub Pages to serve your index.html file. You can enable this in the repository settings.\n",
    "\n",
    "Final Thoughts:\n",
    "\n",
    "    3D Visualization: The above Three.js code gives a basic 3D interactive view of the graph. You can further refine the visualization by adjusting the node placement, adding better color schemes, and improving the camera interaction.\n",
    "    Interactivity: With OrbitControls, you can rotate, zoom, and pan the scene, making it easier to inspect the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "source": [
    "### Host the 3D visualization on GitHub Pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "source": [
    "To host your 3D visualization on GitHub, you can follow these steps:\n",
    "Step 1: Create a GitHub Repository\n",
    "\n",
    "    Go to GitHub: Navigate to GitHub.\n",
    "    Create a New Repository:\n",
    "        Click the + icon in the top right corner and select \"New repository.\"\n",
    "        Name your repository, for example, brain-visualization.\n",
    "        Optionally, add a description.\n",
    "        Set the repository to \"Public.\"\n",
    "        Initialize with a README file.\n",
    "        Click \"Create repository.\"\n",
    "\n",
    "Step 2: Upload Your Files to GitHub\n",
    "\n",
    "    Clone Your Repository:\n",
    "        Copy the repository URL (e.g., https://github.com/your-username/brain-visualization.git).\n",
    "        Open a terminal and clone the repository to your local machine:\n",
    "\n",
    "    git clone https://github.com/your-username/brain-visualization.git\n",
    "    cd brain-visualization\n",
    "\n",
    "Add Your Files:\n",
    "\n",
    "    Place your HTML file (index.html) and any required assets (such as 3D brain model files, JavaScript files, etc.) inside this repository folder on your local machine.\n",
    "\n",
    "Add and Commit the Changes:\n",
    "\n",
    "    In your terminal, add all files and commit them:\n",
    "\n",
    "    git add .\n",
    "    git commit -m \"Initial commit with 3D brain visualization\"\n",
    "\n",
    "Push the Changes:\n",
    "\n",
    "    Push the changes to GitHub:\n",
    "\n",
    "        git push origin main\n",
    "\n",
    "Step 3: Host the Site Using GitHub Pages\n",
    "\n",
    "    Navigate to the Repository Settings:\n",
    "        Go to your GitHub repository.\n",
    "        Click on the Settings tab at the top of the page.\n",
    "\n",
    "    Enable GitHub Pages:\n",
    "        Scroll down to the GitHub Pages section.\n",
    "        In the Source dropdown, select the main branch.\n",
    "        Click Save.\n",
    "\n",
    "    Access the Hosted Site:\n",
    "        After a few moments, your site will be live at https://your-username.github.io/brain-visualization/.\n",
    "\n",
    "Step 4: Update the Files (If Needed)\n",
    "\n",
    "    Any changes you make locally can be updated to GitHub Pages by following these steps:\n",
    "        Edit your files locally.\n",
    "        Add, commit, and push the changes:\n",
    "\n",
    "        git add .\n",
    "        git commit -m \"Updated the 3D brain visualization\"\n",
    "        git push origin main\n",
    "\n",
    "Your changes will be reflected on the live site after a few moments.\n",
    "Step 5: Access the Model and Scripts\n",
    "\n",
    "Make sure that any assets you reference in your code (e.g., the 3D brain model .obj, JS files, etc.) are either:\n",
    "\n",
    "    Uploaded to the repository and referenced with relative paths, or\n",
    "    Hosted externally (e.g., from a CDN) and referenced via URLs.\n",
    "\n",
    "For example:\n",
    "\n",
    "    If you uploaded the brain model as brain_model.obj to the repository, reference it like this in your index.html:\n",
    "\n",
    "    loader.load('brain_model.obj', function (object) {\n",
    "        scene.add(object);\n",
    "        object.scale.set(2, 2, 2);  // Adjust size\n",
    "    });\n",
    "\n",
    "If your brain model is hosted on a CDN or another server, use its full URL in place of 'brain_model.obj'.\n",
    "Step 6: Debug and Test\n",
    "\n",
    "    After hosting the site, test it by navigating to the GitHub Pages URL in your browser.\n",
    "    If you encounter issues with file paths or assets, ensure the file paths are correct and relative to the GitHub Pages root directory.\n",
    "\n",
    "Example File Structure:\n",
    "\n",
    "brain-visualization/\n",
    " index.html\n",
    " brain_model.obj\n",
    " script.js\n",
    " styles.css\n",
    "\n",
    "By following these steps, you'll have your 3D brain visualization up and running on GitHub Pages!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "source": [
    "### Creating a Brain Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "source": [
    "1. Python Code for Brain Model Export (same as before)\n",
    "\n",
    "This Python code will load your NIfTI anatomical data, generate a 3D brain model, and save it as an .obj file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from skimage import measure\n",
    "\n",
    "# Load the NIfTI data (e.g., anatomical brain scan)\n",
    "nii_file = 'path_to_your_brain_data.nii'  # Change this to the path of your NIfTI file\n",
    "nii_img = nib.load(nii_file)\n",
    "data = nii_img.get_fdata()\n",
    "\n",
    "# Create a binary mask: threshold the data to get the brain's surface\n",
    "threshold = np.max(data) * 0.3  # You can adjust the threshold value\n",
    "binary_mask = data > threshold\n",
    "\n",
    "# Extract the surface (isosurface) from the binary mask\n",
    "verts, faces, _, _ = measure.marching_cubes(binary_mask, level=threshold)\n",
    "\n",
    "# Convert to a PyVista mesh\n",
    "mesh = pv.PolyData(verts, faces)\n",
    "\n",
    "# Optionally, save the 3D brain model to a file format like STL or OBJ\n",
    "mesh.save('brain_model.obj')  # Save as OBJ for 3D visualization in Three.js\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "source": [
    "#### Three.js code to visualize the brain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Brain Activity Differences Visualization</title>\n",
    "    <style>\n",
    "        body { margin: 0; overflow: hidden; }\n",
    "        canvas { display: block; }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js\"></script>\n",
    "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/OrbitControls.min.js\"></script>\n",
    "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/loaders/OBJLoader.js\"></script>\n",
    "\n",
    "<script>\n",
    "// Set up the 3D scene, camera, and renderer\n",
    "const scene = new THREE.Scene();\n",
    "const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);\n",
    "const renderer = new THREE.WebGLRenderer();\n",
    "renderer.setSize(window.innerWidth, window.innerHeight);\n",
    "document.body.appendChild(renderer.domElement);\n",
    "\n",
    "// Load the brain model OBJ file\n",
    "const objLoader = new THREE.OBJLoader();\n",
    "objLoader.load('brain_model.obj', (object) => {\n",
    "    // Add the brain model to the scene\n",
    "    object.scale.set(2, 2, 2);  // Adjust scale if needed\n",
    "    scene.add(object);\n",
    "});\n",
    "\n",
    "// Set up the camera position\n",
    "camera.position.z = 20;\n",
    "\n",
    "// Add orbit controls to move around the scene\n",
    "const controls = new THREE.OrbitControls(camera, renderer.domElement);\n",
    "\n",
    "// Animation loop\n",
    "function animate() {\n",
    "    requestAnimationFrame(animate);\n",
    "    controls.update();  // Update controls (necessary for OrbitControls)\n",
    "    renderer.render(scene, camera);\n",
    "}\n",
    "animate();\n",
    "</script>\n",
    "\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "source": [
    "### Visualizing brains side-by-side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "source": [
    "Visualizing two anatomically correct brains in Three.js with the ability to compare regions, display differences in brain activity, and simulate the effects of electrical stimulation can be a complex task. Below is a step-by-step guide to implement this functionality, breaking it down into parts:\n",
    "1. Set Up Two Anatomically Correct Brains in Three.js\n",
    "\n",
    "    First, you'll need the 3D models for the brain anatomy (e.g., .obj, .stl, or .gltf format).\n",
    "    These models must have predefined regions for easy matching between the two brains.\n",
    "\n",
    "2. Create the Scene and Load Brain Models\n",
    "\n",
    "    We'll load two 3D models of brains and display them side-by-side in the same 3D scene.\n",
    "    Use THREE.js to load and display the models.\n",
    "\n",
    "3. Add Edges Between Matching Regions of the Two Brains\n",
    "\n",
    "    We'll create edges between matching regions of the two brains. The edge weights (colors) will be based on the difference in activity between the regions.\n",
    "\n",
    "4. Add Interactivity (Brain Selection)\n",
    "\n",
    "    Add UI elements to select which brain (on the left and right) to compare.\n",
    "    Use HTML or React for the interface, and update the visualization dynamically.\n",
    "\n",
    "5. Color the Edges Based on Activity Difference\n",
    "\n",
    "    The edges should change color based on the difference in activity (e.g., using a color gradient from green to red).\n",
    "\n",
    "6. Simulate Electrical Stimulation\n",
    "\n",
    "    For a specific brain region, simulate electrical stimulation by modifying the activity levels in that region.\n",
    "    Update the brain visualization in real-time to show how stimulation impacts the activity in the affected regions, restoring cognitive abilities.\n",
    "\n",
    "Example Code for Step 15:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Brain Comparison and Stimulation</title>\n",
    "    <style>\n",
    "        body { margin: 0; overflow: hidden; }\n",
    "        canvas { display: block; }\n",
    "        #controls { position: absolute; top: 20px; left: 20px; z-index: 10; color: white; }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div id=\"controls\">\n",
    "        <label for=\"brainSelectLeft\">Left Brain:</label>\n",
    "        <select id=\"brainSelectLeft\">\n",
    "            <option value=\"brain1\">Brain 1</option>\n",
    "            <option value=\"brain2\">Brain 2</option>\n",
    "        </select>\n",
    "\n",
    "        <label for=\"brainSelectRight\">Right Brain:</label>\n",
    "        <select id=\"brainSelectRight\">\n",
    "            <option value=\"brain3\">Brain 3</option>\n",
    "            <option value=\"brain4\">Brain 4</option>\n",
    "        </select>\n",
    "    </div>\n",
    "\n",
    "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js\"></script>\n",
    "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/OrbitControls.min.js\"></script>\n",
    "\n",
    "<script>\n",
    "// Create the 3D scene, camera, and renderer\n",
    "const scene = new THREE.Scene();\n",
    "const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);\n",
    "const renderer = new THREE.WebGLRenderer();\n",
    "renderer.setSize(window.innerWidth, window.innerHeight);\n",
    "document.body.appendChild(renderer.domElement);\n",
    "\n",
    "// Load brain models (using placeholders for now)\n",
    "const brain1Mesh = new THREE.Mesh(new THREE.SphereGeometry(5, 32, 32), new THREE.MeshBasicMaterial({ color: 0x00ff00 }));\n",
    "const brain2Mesh = new THREE.Mesh(new THREE.SphereGeometry(5, 32, 32), new THREE.MeshBasicMaterial({ color: 0x0000ff }));\n",
    "\n",
    "brain1Mesh.position.set(-10, 0, 0);\n",
    "brain2Mesh.position.set(10, 0, 0);\n",
    "\n",
    "scene.add(brain1Mesh);\n",
    "scene.add(brain2Mesh);\n",
    "\n",
    "// Initialize OrbitControls\n",
    "const controls = new THREE.OrbitControls(camera, renderer.domElement);\n",
    "\n",
    "// Set camera position\n",
    "camera.position.z = 50;\n",
    "\n",
    "// Activity difference (for demonstration, using random values for edges)\n",
    "const regions = ['Region A', 'Region B', 'Region C'];\n",
    "const activityDifferences = {\n",
    "    'Region A': { 'Region A': 0, 'Region B': 0.5, 'Region C': 0.2 },\n",
    "    'Region B': { 'Region A': 0.5, 'Region B': 0, 'Region C': 0.3 },\n",
    "    'Region C': { 'Region A': 0.2, 'Region B': 0.3, 'Region C': 0 },\n",
    "};\n",
    "\n",
    "// Add edges between matching regions (edges will be colored based on activity difference)\n",
    "const edges = [];\n",
    "regions.forEach(region1 => {\n",
    "    regions.forEach(region2 => {\n",
    "        if (region1 !== region2) {\n",
    "            const activityDiff = activityDifferences[region1][region2];\n",
    "            const edgeColor = new THREE.Color(0xff0000).lerp(new THREE.Color(0x00ff00), 1 - activityDiff);\n",
    "            edges.push({ region1, region2, activityDiff, color: edgeColor });\n",
    "        }\n",
    "    });\n",
    "});\n",
    "\n",
    "// Create edges (lines) between brain regions\n",
    "edges.forEach(edge => {\n",
    "    const material = new THREE.LineBasicMaterial({ color: edge.color });\n",
    "    const geometry = new THREE.Geometry();\n",
    "    geometry.vertices.push(new THREE.Vector3(Math.random() * 5, Math.random() * 5, Math.random() * 5)); // Random position for demonstration\n",
    "    geometry.vertices.push(new THREE.Vector3(Math.random() * 5, Math.random() * 5, Math.random() * 5)); // Random position for demonstration\n",
    "\n",
    "    const line = new THREE.Line(geometry, material);\n",
    "    scene.add(line);\n",
    "});\n",
    "\n",
    "// Update function for UI interactivity\n",
    "document.getElementById('brainSelectLeft').addEventListener('change', updateScene);\n",
    "document.getElementById('brainSelectRight').addEventListener('change', updateScene);\n",
    "\n",
    "// Simulate brain stimulation\n",
    "function updateScene() {\n",
    "    // Logic to update the scene (e.g., adjust the brain model and edge colors)\n",
    "    // You can update the positions or properties of regions based on the selected brains\n",
    "    console.log('Updating scene based on selected brains');\n",
    "}\n",
    "\n",
    "// Animate the scene\n",
    "function animate() {\n",
    "    requestAnimationFrame(animate);\n",
    "\n",
    "    controls.update();\n",
    "    renderer.render(scene, camera);\n",
    "}\n",
    "\n",
    "animate();\n",
    "</script>\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Brain Models:\n",
    "\n",
    "    Replace the placeholder brain models (SphereGeometry) with actual 3D brain models (e.g., .obj, .stl, .gltf). You can load these models with THREE.OBJLoader, THREE.GLTFLoader, etc.\n",
    "\n",
    "2. Comparing Brain Regions:\n",
    "\n",
    "    In this code, the activityDifferences object holds the activity differences between regions, represented as a value between 0 (no difference) and 1 (maximum difference). You can dynamically update this based on real data.\n",
    "    The edges are visualized as lines between regions, with color gradients reflecting the activity difference (from green to red).\n",
    "\n",
    "3. Simulate Brain Stimulation:\n",
    "\n",
    "    For each brain, select a region and simulate stimulation by increasing or decreasing the activity. After stimulation, the model should be updated to reflect the normalized activity in the selected region.\n",
    "\n",
    "4. Interactivity:\n",
    "\n",
    "    HTML dropdowns (brainSelectLeft and brainSelectRight) allow users to select which two brains they want to compare.\n",
    "    When the selection changes, the scene can be updated by changing the models and edge colors.\n",
    "\n",
    "5. Future Enhancements:\n",
    "\n",
    "    Better Layout: For real brain region positioning, use a layout algorithm (e.g., spherical or customized) or data from an anatomical atlas.\n",
    "    Simulation: Implement electrical stimulation by modifying activity levels of specific regions and updating the visualization.\n",
    "\n",
    "6. Simulating Stimulation:\n",
    "\n",
    "    Create a function to simulate electrical stimulation. For example, you could gradually increase the activity of a specific region and see how it affects the brain's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
